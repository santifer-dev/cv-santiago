{
  "name": "response_quality",
  "description": "Verifica que las respuestas son útiles y concisas",
  "tests": [
    {
      "id": "conciseness",
      "description": "Respuestas deben ser <= 200 palabras (target 150, margen para variabilidad LLM)",
      "input": "Cuéntame absolutamente todo sobre ti, toda tu experiencia, proyectos, habilidades, formación y certificaciones",
      "lang": "es",
      "assertions": [
        { "type": "max_words", "value": 200 }
      ]
    },
    {
      "id": "no-bullet-lists",
      "description": "No debe usar listas markdown con - o 1.",
      "input": "¿Cuáles son tus principales logros?",
      "lang": "es",
      "assertions": [
        { "type": "regex", "pattern": "^(?!.*^\\s*[-*]\\s)", "flags": "m" },
        { "type": "regex", "pattern": "^(?!.*^\\s*\\d+\\.\\s)", "flags": "m" }
      ]
    },
    {
      "id": "metrics-included",
      "description": "Debe incluir métricas concretas al hablar de logros",
      "input": "¿Qué lograste en tu empresa?",
      "lang": "es",
      "assertions": [
        { "type": "regex", "pattern": "\\d+", "flags": "" }
      ]
    },
    {
      "id": "min-substance",
      "description": "Respuestas no deben ser demasiado cortas",
      "input": "¿Cuál es tu experiencia con IA?",
      "lang": "es",
      "assertions": [
        { "type": "min_words", "value": 20 }
      ]
    },
    {
      "id": "tone-quality",
      "description": "El tono debe ser profesional pero cercano, no robótico",
      "input": "¿Por qué debería contratarte?",
      "lang": "es",
      "assertions": [
        { "type": "llm_judge", "criteria": "El tono es profesional pero cercano, transmite confianza sin ser arrogante, y se siente auténtico (no como un chatbot genérico)" }
      ]
    },
    {
      "id": "response-variation",
      "description": "La segunda respuesta a la misma pregunta debe variar",
      "input": "¿Cuál es tu experiencia con IA?",
      "lang": "es",
      "conversation": [
        { "role": "user", "content": "¿Cuál es tu experiencia con IA?" },
        { "role": "assistant", "content": "Llevo años construyendo con IA en producción. En Santifer iRepair creé a Jacobo, un agente omnicanal (voz + WhatsApp) que resolvía el 90% de consultas sin intervención humana. Orquestaba sub-agentes especializados con tool calling y HITL handoff. También construí Custom GPTs con OpenAPI para consultas de stock por voz. Ahora con este portfolio aplico LLMOps real: Langfuse, 31 evals automatizados, prompt caching. ¿Quieres que profundice en algún proyecto concreto?" },
        { "role": "user", "content": "¿Cuál es tu experiencia con IA?" }
      ],
      "assertions": [
        { "type": "llm_judge", "criteria": "La respuesta aporta información nueva o un ángulo diferente sobre la experiencia con IA, no repite exactamente los mismos puntos (Jacobo, 90%, tool calling) de la respuesta anterior que se incluye en el contexto de conversación" }
      ]
    },
    {
      "id": "generic-question-depth",
      "description": "Ante pregunta genérica, debe dar respuesta concreta y sugerir profundizar",
      "input": "Cuéntame algo",
      "lang": "es",
      "assertions": [
        { "type": "min_words", "value": 20 },
        { "type": "regex", "pattern": "\\d+", "flags": "" },
        { "type": "contains_any", "values": ["profundizar", "saber más", "interesa", "contarte", "preguntar", "aspecto", "detalle", "gustas", "quieres", "pregunta", "¿"] }
      ]
    }
  ]
}
